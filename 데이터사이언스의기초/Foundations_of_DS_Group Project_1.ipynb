{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Interpret k-NN classification code line by line\n",
    "\n",
    "## Group Members\n",
    "\n",
    "### - Cho Yunah: 2017010255 \n",
    "\n",
    "### - Lee Sihyeon: 2017010146 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Haberman's Survival Data Set\n",
    "\n",
    "This is a reimplementation of the K-Nearest Neighbors algorithm using plain Python.\n",
    "\n",
    "In my opinion it is important to understand the \"low level\", not just the abstraction.\n",
    "\n",
    "Data Set: Haberman's Survival Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math # import math module for mathematical computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] # make a list named 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the data and append it to the list\n",
    "\n",
    " [age_of_the_patient, year_of_operation, number_of_nodes_detected, survival_status]\n",
    " \n",
    " \n",
    " Check the data set's link above for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('haberman.data', 'r') as f: # open 'haberman.data' as r mode and save in f\n",
    "    for line in f.readlines(): # f.readlines() will read each line in the file\n",
    "        atributes = line.strip('\\n').split(',') # the variable 'atributes' will remove the blanks, tabs, and enters at the beginning and end of the sentence and save the new lists of strings divided by ','.\n",
    "        data.append([int(x) for x in atributes]) # change the each data in 'atributes' to integer type and but in the list named 'data'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Auxiliary function to help the visualization\n",
    "\n",
    "Also returns key information of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_dataset(data, verbose=True): # set the new function called 'info_dataset', turn on the verbose mode\n",
    "    label1, label2 = 0, 0 # create 'label1','label2' and set to zero\n",
    "    data_size = len(data) # 'data_size' shows the length of data\n",
    "    for datum in data: \n",
    "        if datum[-1] == 1:\n",
    "            label1 += 1 # if the last component of the lists of list 'data' is 1 count them in 'label1'\n",
    "        else:\n",
    "            label2 += 1 # if the last component of the lists of list 'data' is not 1 count them in 'label2'\n",
    "    if verbose:\n",
    "        print('Total of samples: %d' % data_size)\n",
    "        print('Total label 1: %d' % label1)\n",
    "        print('Total label 2: %d' % label2)\n",
    "    return [len(data), label1, label2] # if for function ends(verbose = true) execute print functions\n",
    "\n",
    "# * verbose: By showing the details at boot time, you can see where there was a delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of samples: 306\n",
      "Total label 1: 225\n",
      "Total label 2: 81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[306, 225, 81]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_dataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the train/total percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.6 # devide train/total in percentage of 0.6\n",
    "_, label1, label2 = info_dataset(data,False) # save len(data), label1, label2 in _, label1, label2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split the data set into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = [], [] # create empty list called 'train_set', 'test_set'\n",
    "max_label1, max_label2 = int(p * label1), int(p * label2) # set 'max_label1' and 'max_label2' to 135 which is 0.6 of label 1(225) and 48.6, which is 0.6 of label 2 (81)\n",
    "total_label1, total_label2 = 0, 0 # initializing variables into 0\n",
    "for sample in data:\n",
    "    if (total_label1 + total_label2) < (max_label1 + max_label2):\n",
    "        train_set.append(sample) # if it is true put sample list in 'train_set'\n",
    "        if sample[-1] == 1 and total_label1 < max_label1:\n",
    "            total_label1 += 1 # if the last number of sample is 1 and 'tota_label1' is less than 'max_label1' count as 'tota_label1'\n",
    "        else:\n",
    "            total_label2 += 1 # if not, count as 'tota_label2'\n",
    "    else:\n",
    "        test_set.append(sample) # otherwise put sample list in 'test_set'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define function to calculate the euclidian distance between two points\n",
    "\n",
    "Euclidian Distance - Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_dist(p1, p2): # manhattan distance function with variable 'p1' and 'p2'\n",
    "    if len(p1)==len(p2): # check if the length of two points are same\n",
    "        r = 0 # initalize distance into 0 by variable 'r'\n",
    "        for i in range(0, len(p1)):\n",
    "            r += abs(p1[i]-p2[i]) # sum of the absolute value of a difference in two points of coordinates\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_dist(p1,p2): # euclidian distance function with variable 'p1' and 'p2'\n",
    "    dim, sum_ = len(p1),0 # initalize 'dim' and 'sum_' into 'len(p1)'and zero \n",
    "    for index in range(dim-1):\n",
    "        sum_ += math.pow(p1[index]-p2[index],2) # math.pow(x,n) += (p1[index]-p2[index]) updating by continuously adding the squared(2) [p1[index]-p2[index]]\n",
    "    return math.sqrt(sum_) # square root of 'sum_' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculates the distance between a given sample and every other in the train set\n",
    "\n",
    "Feeds its distances to a dictionary, the sort it and gets the nearest K neighbors; Then it counts witch of the labels is the most recurring, and returns it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train_set, new_sample, K): # define the knn function that receives train_set, new_samle, and K as factors\n",
    "    dists, train_size = {}, len(train_set) # Create a dictionary called 'dists' and put the length value of 'train_set' in 'train_size'\n",
    "    \n",
    "    for i in range(train_size): # repeat as 'train_size'\n",
    "        d = euclidian_dist(train_set[i], new_sample) # 'd' is euclidian distance between 'train_set' and 'new_sample'\n",
    "        dists[i] = d # put in the dictionary 'dists'\n",
    "        # get eucladian distance between 'test_set' and all values of 'train_set' and put it in 'dists'\n",
    "    \n",
    "    k_neighbors = sorted(dists, key=dists.get)[:K]\n",
    "    # sort the data in ascending order based on the key value\n",
    "    # take out as many index as K and put it in k_neighbors.\n",
    "    \n",
    "    qty_label1, qty_label2 = 0, 0 # Initialize 'qty_label1' and 'qty_label2' to zero\n",
    "    for index in k_neighbors: # 'index' from 'k_neighbors' to object 'index' and start for\n",
    "        if train_set[index][-1] == 1: # # if the last value of each of the 12 selected values is one,\n",
    "            qty_label1 += 1 # renew by adding 1 to 'qty_label1'\n",
    "        else: # If the last value of each of the 12 selected values is two,\n",
    "            qty_label2 += 1 # renew by adding 1 to 'qty_label2'\n",
    "            \n",
    "    if qty_label1 > qty_label2: # If the value classified as 1 is more than the value classified as 2,\n",
    "        return 1\n",
    "    else: # If there are more values classified as 2 than as 1,\n",
    "        return 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55, 58, 0, 1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(test_set[0]) # let's check the first list of lists in 'test_set'\n",
    "print(knn(train_set, test_set[0], 12)) # with the knn function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Counts the correct predictions of the test set with a given K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, K = 0, 15 # initialize 'correct' to 0 and 'K' to 15\n",
    "for sample in test_set: # put the values in 'test_set' one by one into the 'sample' object and start for\n",
    "    label = knn(train_set, sample, K)\n",
    "    # use euclidean distance from train_set using knn function\n",
    "    # The top 12 values in ascending order are returned to 1 if 1 is more frequent, and 2 if 2 is more frequent, and the number is entered into the 'label' object.\n",
    "\n",
    "    if sample[-1] == label: # If the last value of the sample is the same as the value obtained using the nn function,\n",
    "        correct += 1 # count the number in 'correct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 183\n",
      "Test set size: 123\n",
      "Correct predicitons: 93\n",
      "Accuracy: 50.82%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size: %d\" % len(train_set))\n",
    "print(\"Test set size: %d\" % len(test_set))\n",
    "print(\"Correct predicitons: %d\" % correct)\n",
    "print(\"Accuracy: %.2f%%\" % (100 * correct / len(train_set)))\n",
    "# The ratio is obtained by dividing the number of times the last value of the sample and the value obtained using the 'knn function' are same by the total number of 'train_set'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
